{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9239476c",
   "metadata": {},
   "source": [
    "# 基于Mindspore构造负对数似然损失函数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d6e0db7",
   "metadata": {},
   "source": [
    " 本小节主要介绍构造负对数似然损失函数的设计，使用Negative Log-Likelihood Loss损失函数作为讲解实例。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e150d15",
   "metadata": {},
   "source": [
    "# 1. 实验目的\n",
    "- 理解Negative Log-Likelihood Loss损失函数的意义\n",
    "- 使用MindSpore框架实现的Negative Log-Likelihood Loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96f008e7",
   "metadata": {},
   "source": [
    "# 2. Negative Log-Likelihood Loss损失函数知识点介绍\n",
    "\n",
    "负对数似然损失函数（Negative Log-Likelihood Loss）是在概率建模和分类任务中常用的损失函数之一。它通常用于多类别分类问题，其中每个样本被分为多个互斥的类别。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aea6531c",
   "metadata": {},
   "source": [
    "## 2.1 基础知识\n",
    "- 交叉熵函数和负对数似然损失函数在某种程度上是等价的。在分类任务中，交叉熵函数通常用于衡量模型输出和真实标签之间的差异，而负对数似然损失函数则用于最大化模型对观测数据的似然。\n",
    "- 对于二分类问题，交叉熵函数和负对数似然损失函数是完全等价的。对于多类别分类问题，两者在形式上稍有不同，但是在数学上是等价的。具体而言，对于多类别分类问题，交叉熵函数是对所有类别的负对数似然损失函数的平均值。\n",
    "- 需要注意的是，使用交叉熵函数计算损失时，通常要结合softmax或sigmoid等激活函数的输出，以将输出值转化为概率分布。而负对数似然损失函数通常用于直接计算概率分布的对数似然。\n",
    "- 总的来说，交叉熵函数和负对数似然损失函数在分类任务中是等价的，可以根据实际需求选择使用其中之一。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "374942a7",
   "metadata": {},
   "source": [
    "## 2.2 似然函数\n",
    "\n",
    "假设X 是观测结果序列，它的概率分布$f_x$依赖于参数$\\theta$ ，则似然函数表示为\n",
    "\n",
    "\n",
    "$$L(\\theta|x) = f_\\theta(x) =P_\\theta(X=x)$$\n",
    "\n",
    "$L(\\theta|x)$为参数$\\theta$的似然函数,x为随机变量X的输出。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c1619e5",
   "metadata": {},
   "source": [
    "## 2.3 负对数似然损失函数\n",
    "负对数似然损失的数学定义如下：\n",
    "\n",
    "$$L(x, y) = \\frac {-1}{N} * ∑(∑(y_i) * log(x_i))$$\n",
    "\n",
    "其中，N表示样本数量，∑表示对所有样本和类别的求和操作。\n",
    "\n",
    "负对数似然损失是将真实标签和模型预测的概率分布进行逐元素相乘，然后取对数，并求和得到损失值。\n",
    "损失越小，模型的预测概率分布与真实标签越接近。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe00aa61",
   "metadata": {},
   "source": [
    "NLLLoss函数虽然叫负对数似然损失函数，但是该函数内部并没有像公式里那样进行了对数计算，而是在激活函数上使用了nn.LogSoftmax()函数。\n",
    "所以NLLLoss函数只是做了求和取平均然后再取反的计算，在使用时要配合logsoftmax函数一起使用，或者直接使用交叉熵损失函数。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c63e97dd",
   "metadata": {},
   "source": [
    "# 3. 实验环境\n",
    "在动手进行实践之前，需要注意以下几点：\n",
    "* 确保实验环境正确安装，包括安装MindSpore。安装过程：首先登录[MindSpore官网安装页面](https://www.mindspore.cn/install)，根据安装指南下载安装包及查询相关文档。同时，官网环境安装也可以按下表说明找到对应环境搭建文档链接，根据环境搭建手册配置对应的实验环境。\n",
    "* 推荐使用交互式的计算环境Jupyter Notebook，其交互性强，易于可视化，适合频繁修改的数据分析实验环境。\n",
    "* 实验也可以在华为云一站式的AI开发平台ModelArts上完成。\n",
    "* 推荐实验环境：MindSpore版本=2.0；Python环境=3.7\n",
    "\n",
    "\n",
    "|  硬件平台 |  操作系统  | 软件环境 | 开发环境 | 环境搭建链接 |\n",
    "| :-----:| :----: | :----: |:----:   |:----:   |\n",
    "| CPU | Windows-x64 | MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.1节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| GPU CUDA 10.1|Linux-x86_64| MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.2节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| Ascend 910  | Linux-x86_64| MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第四章](./MindSpore环境搭建实验手册.docx)|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fd9767d",
   "metadata": {},
   "source": [
    "# 4. 数据处理\n",
    "\n",
    "## 4.1 数据准备\n",
    "\n",
    "   在本次实验中，我们使用numpy随机生成的样本数据集进行测试。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8339005",
   "metadata": {},
   "source": [
    "## 4.2 数据处理\n",
    "\n",
    "使用numpy生成测试数据：\n",
    "\n",
    "$$[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]$$\n",
    "\n",
    "创建2个样本在3个类别的预测概率：\n",
    "\n",
    "$$[[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]] $$\n",
    "\n",
    "\n",
    "创建它们对应的标签：\n",
    "$$[0, 2] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8870544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入mindspore框架。\n",
    "import mindspore\n",
    "#将Model用于创建模型对象，完成网络搭建和编译，并用于训练和评估\n",
    "from mindspore import nn \n",
    "#导入可用于Cell的构造函数的算子。\n",
    "from mindspore import ops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "962a89d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[1, 3], dtype=Float32, value=\n",
       " [[ 5.00000000e+00,  7.00000000e+00,  9.00000000e+00]]),\n",
       " Tensor(shape=[2, 1], dtype=Float32, value=\n",
       " [[ 6.00000000e+00],\n",
       "  [ 1.50000000e+01]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 给定一个矩阵X，我们可以对所有元素求和。\n",
    "X = mindspore.Tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], mindspore.float32)\n",
    "X.sum(0, keepdims=True), X.sum(1, keepdims=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7aba6f6",
   "metadata": {},
   "source": [
    "# 5、实验过程\n",
    "\n",
    "模型的构建包括如下部分：\n",
    "- 导入库和函数\n",
    "- 自定义损失函数Negative Log-Likelihood Loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "524031d6",
   "metadata": {},
   "source": [
    "## 5.1 导入相关库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c978c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mindspore\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "import mindspore.numpy as mnp\n",
    "from mindspore import Tensor, Parameter\n",
    "from mindspore.common.initializer import initializer, Zero, Normal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60ad663f",
   "metadata": {},
   "source": [
    "# 6、模型构建\n",
    "\n",
    "损失函数NLLLoss自定义完成后，创建一个数据样本及它们对应的标签y，使用x作为x_sample中概率的索引来实现负对数似然损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09a5a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax函数用于将其转换为概率分布。softmax函数对每个样本（行）的元素进行指数运算，\n",
    "# 然后对每个样本的元素求和，得到一个分区（partition）向量，其中每个元素表示对应样本的所有类别的指数和。\n",
    "def softmax(X):\n",
    "    X_exp = ops.exp(X)\n",
    "    partition = X_exp.sum(1, keepdims=True)\n",
    "    return X_exp / partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "948d4198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "class Net(nn.Cell):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super().__init__\n",
    "        self.W = Parameter(initializer(Normal(0.01, 0), (num_inputs, num_outputs), mindspore.float32))\n",
    "        self.b = Parameter(initializer(Zero(), num_outputs, mindspore.float32))\n",
    "\n",
    "    def construct(self, X):\n",
    "        return softmax(ops.matmul(X.reshape((-1, self.W.shape[0])), self.W) + self.b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7978ee1",
   "metadata": {},
   "source": [
    "创建一个数据样本x_sample，其中包含2个样本在3个类别的预测概率，及它们对应的标签x，使用x作为x_sample中概率的索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d90c909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[2], dtype=Float32, value= [ 1.00000001e-01,  5.00000000e-01])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成标签\n",
    "x = mindspore.Tensor([0, 2], mindspore.int32)\n",
    "# 生成样本\n",
    "x_sample = mindspore.Tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]], mindspore.float32)\n",
    "x_sample[[0, 1], x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9ef7b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[2], dtype=Float32, value= [ 2.30258751e+00,  6.93148613e-01])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实现负对数似然损失函数\n",
    "def NLLLoss(x_sample, x):\n",
    "    return -mnp.log(x_sample[mnp.arange(x_sample.shape[0]), x])\n",
    "NLLLoss(x_sample, x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25765d55",
   "metadata": {},
   "source": [
    "# 7、模型预测\n",
    "\n",
    "定义一个计算精确度的函数，输入预测值和真实值，选择NLLLoss计算模型的精确度。accuracy函数接收两个输入：x_sample表示模型的预测输出，x表示真实的目标标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a0530d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算预测正确的数量\n",
    "def accuracy(x_sample, x): \n",
    "    # 函数检查x_sample的形状是否大于1维且第二个维度大于1。\n",
    "    # 如果满足条件，说明x_sample是多类别预测的概率分布结果，需要使用argmax函数获取最大概率对应的类别索引。 \n",
    "    if len(x_sample.shape) > 1 and x_sample.shape[1] > 1:  \n",
    "        x_sample = x_sample.argmax(axis=1)\n",
    "    # 使用float(cmp.sum())计算预测正确的数量，cmp.sum()返回布尔数组中为True的元素数量，即预测正确的数量。              \n",
    "    cmp = x_sample.asnumpy() == x.asnumpy()            \n",
    "    return float(cmp.sum())\n",
    "\n",
    "# 将预测正确的数量除以样本的总数量，得到准确率。   \n",
    "accuracy(x_sample, x) / len(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
