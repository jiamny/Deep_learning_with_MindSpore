{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于MindSpore实现多分类损失函数\n",
    "本小节主要介绍多分类损失函数的原理，并使用MIndspore实现。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、实验目的\n",
    "- 了解多分类损失函数原理。\n",
    "- 掌握如何使用MIndspore实现多分类损失函数。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、多分类损失函数原理介绍\n",
    "二分类损失函数中定义了一个简单的平均绝对误差损失函数MAELoss，但许多深度学习应用的数据集较复杂，如目标检测网络Faster R-CNN的数据中就包含多个标签，而非简单的一条数据对应一个标签，这时损失函数的定义和使用略有不同。  \n",
    "针对本实验中创建的多标签数据集，定义多标签损失函数MAELossForMultiLabel。\n",
    "$$ loss\\ 1=\\frac{1}{m}\\ \\sum_{i=1}^{m}\\left|y1_i-f\\left(x_i\\right)\\right| $$\n",
    "$$ loss\\ 2=\\frac{1}{m}\\ \\sum_{i=1}^{m}\\left|y2_i-f\\left(x_i\\right)\\right| $$\n",
    "$$ loss=\\frac{\\left(loss1+loss2\\right)}{2} $$\n",
    "上式中，f(x)为样例标签的预测值，y1和y2为样例标签的真实值，$loss\\ 1$为预测值与真实值y1之间距离的平均值，$loss\\ 2$为预测值与真实值y2之间距离的平均值，loss为损失值$loss\\ 1$与损失值$loss\\ 2$平均值。  \n",
    "在 MAELossForMultilabel中的construct方法的输入有三个，预测值base，真实值target1和target2，在construct中分别计算预测值与真实值target1、预测值与真实值target2之间的误差，将两误差取平均后作为最终的损失函数值。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、实验环境\n",
    "在动手进行实践之前，需要注意以下几点：\n",
    "* 确保实验环境正确安装，包括安装MindSpore。安装过程：首先登录[MindSpore官网安装页面](https://www.mindspore.cn/install)，根据安装指南下载安装包及查询相关文档。同时，官网环境安装也可以按下表说明找到对应环境搭建文档链接，根据环境搭建手册配置对应的实验环境。\n",
    "* 推荐使用交互式的计算环境Jupyter Notebook，其交互性强，易于可视化，适合频繁修改的数据分析实验环境。\n",
    "* 实验也可以在华为云一站式的AI开发平台ModelArts上完成。\n",
    "* 推荐实验环境：MindSpore版本=MindSpore 2.0；Python环境=3.7\n",
    "\n",
    "\n",
    "|  硬件平台 |  操作系统  | 软件环境 | 开发环境 | 环境搭建链接 |\n",
    "| :-----:| :----: | :----: |:----:   |:----:   |\n",
    "| CPU | Windows-x64 | MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.1节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| GPU CUDA 10.1|Linux-x86_64| MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.2节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| Ascend 910  | Linux-x86_64| MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第四章](./MindSpore环境搭建实验手册.docx)|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、数据处理"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 构建多标签数据集\n",
    "Numpy模块主要用于数据的基本运算操作。MindSpore相关模块主要用于搭建网络、调用优化器、读取数据集和将数据集处理成网络的标准输入格式。  \n",
    "数据集的两个标签分别由\n",
    "$$y_1=2x+3+{noise}_1$$\n",
    "$$y_2=2x+3+{noise}_2$$\n",
    "生成。其中${noise}_1$和${noise}_2$为服从标准正态分布的随机值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from mindspore import dataset as ds\n",
    "import mindspore.nn as nn\n",
    "import mindspore as ms\n",
    "\n",
    "ms.set_context(mode=ms.GRAPH_MODE, device_target='CPU')\n",
    "\n",
    "# 生成带有两个标签的数据集\n",
    "def get_multilabel_data(num, w=2.0, b=3.0):\n",
    "    for _ in range(num):\n",
    "        x = np.random.uniform(-10.0, 10.0)\n",
    "        # noise1和noise2为服从标准正态分布的随机值\n",
    "        noise1 = np.random.normal(0, 1)\n",
    "        noise2 = np.random.normal(-1, 1)\n",
    "        # 定义第一个标签\n",
    "        y1 = x * w + b + noise1                   \n",
    "        # 定义第二个标签\n",
    "        y2 = x * w + b + noise2                   \n",
    "        yield np.array([x]).astype(np.float32), np.array([y1]).astype(np.float32), np.array([y2]).astype(np.float32)\n",
    "\n",
    "def create_multilabel_dataset(num_data, batch_size=16):\n",
    "    dataset = ds.GeneratorDataset(list(get_multilabel_data(num_data)), column_names=['data', 'label1', 'label2'])\n",
    "    # 每个batch有16个数据\n",
    "    dataset = dataset.batch(batch_size) \n",
    "    return dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5、模型构建"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 多标签损失函数\n",
    "定义多标签损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义多标签损失函数\n",
    "class MAELossForMultiLabel(nn.LossBase):\n",
    "    def __init__(self, reduction=\"mean\"):\n",
    "        super(MAELossForMultiLabel, self).__init__(reduction)\n",
    "        self.abs = ops.abs\n",
    "\n",
    "    def construct(self, base, target1, target2):\n",
    "        # 计算第一个标签的误差\n",
    "        x1 = self.abs(base - target1)\n",
    "        # 计算第二个标签的误差\n",
    "        x2 = self.abs(base - target2)\n",
    "        # 将两误差取平均后作为最终的损失函数值                           \n",
    "        return (self.get_loss(x1) + self.get_loss(x2))/2        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 定义损失函数\n",
    "使用 Model 关联指定的前向网络、损失函数和优化器时，因 Model 内默认使用的 nn.WithLossCell 只接受两个输入： data 和 label ，故不适用于多标签场景。在多标签场景下，若想使用 Model 进行模型训练，则需事先把前向网络与多标签损失函数关联起来，即自定义损失网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义损失网络\n",
    "class CustomWithLossCell(nn.Cell):\n",
    "    def __init__(self, backbone, loss_fn):\n",
    "        super(CustomWithLossCell, self).__init__(auto_prefix=False)\n",
    "        self._backbone = backbone\n",
    "        self._loss_fn = loss_fn\n",
    "\n",
    "    def construct(self, data, label1, label2):\n",
    "        output = self._backbone(data)\n",
    "        return self._loss_fn(output, label1, label2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 定义网络模型\n",
    "定义线性回归网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.common.initializer import Normal\n",
    "import mindspore.ops as ops\n",
    "from mindspore.train import LossMonitor\n",
    "# 定义线性回归网络\n",
    "class LinearNet(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.fc = nn.Dense(1, 1, Normal(0.02), Normal(0.02))\n",
    "\n",
    "    def construct(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6、模型训练\n",
    "定义多标签损失函数、损失网络和优化器，并开始模型的训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1, loss is 11.168766021728516\n",
      "epoch: 1 step: 2, loss is 9.674881935119629\n",
      "epoch: 1 step: 3, loss is 7.414841651916504\n",
      "epoch: 1 step: 4, loss is 8.943695068359375\n",
      "epoch: 1 step: 5, loss is 8.155509948730469\n",
      "epoch: 1 step: 6, loss is 10.243484497070312\n",
      "epoch: 1 step: 7, loss is 7.751708984375\n",
      "epoch: 1 step: 8, loss is 8.45167350769043\n",
      "epoch: 1 step: 9, loss is 6.604907989501953\n",
      "epoch: 1 step: 10, loss is 5.796879768371582\n",
      "epoch: 2 step: 1, loss is 7.4184675216674805\n",
      "epoch: 2 step: 2, loss is 4.518697738647461\n",
      "epoch: 2 step: 3, loss is 2.9617834091186523\n",
      "epoch: 2 step: 4, loss is 2.656360626220703\n",
      "epoch: 2 step: 5, loss is 3.38094425201416\n",
      "epoch: 2 step: 6, loss is 2.7276973724365234\n",
      "epoch: 2 step: 7, loss is 2.4612107276916504\n",
      "epoch: 2 step: 8, loss is 2.5444395542144775\n",
      "epoch: 2 step: 9, loss is 2.829113006591797\n",
      "epoch: 2 step: 10, loss is 2.8429994583129883\n",
      "epoch: 3 step: 1, loss is 2.5914132595062256\n",
      "epoch: 3 step: 2, loss is 2.4165596961975098\n",
      "epoch: 3 step: 3, loss is 3.707446336746216\n",
      "epoch: 3 step: 4, loss is 3.375732421875\n",
      "epoch: 3 step: 5, loss is 4.06792688369751\n",
      "epoch: 3 step: 6, loss is 3.430602550506592\n",
      "epoch: 3 step: 7, loss is 2.4878311157226562\n",
      "epoch: 3 step: 8, loss is 1.9978342056274414\n",
      "epoch: 3 step: 9, loss is 2.429102897644043\n",
      "epoch: 3 step: 10, loss is 2.9037740230560303\n",
      "epoch: 4 step: 1, loss is 2.7877798080444336\n",
      "epoch: 4 step: 2, loss is 2.0542638301849365\n",
      "epoch: 4 step: 3, loss is 2.0772130489349365\n",
      "epoch: 4 step: 4, loss is 2.043592929840088\n",
      "epoch: 4 step: 5, loss is 1.84449303150177\n",
      "epoch: 4 step: 6, loss is 2.126824378967285\n",
      "epoch: 4 step: 7, loss is 2.092791795730591\n",
      "epoch: 4 step: 8, loss is 2.211211919784546\n",
      "epoch: 4 step: 9, loss is 1.8839986324310303\n",
      "epoch: 4 step: 10, loss is 1.914844036102295\n",
      "epoch: 5 step: 1, loss is 2.113081455230713\n",
      "epoch: 5 step: 2, loss is 2.129089832305908\n",
      "epoch: 5 step: 3, loss is 2.1099791526794434\n",
      "epoch: 5 step: 4, loss is 1.5075244903564453\n",
      "epoch: 5 step: 5, loss is 1.7547152042388916\n",
      "epoch: 5 step: 6, loss is 1.7196049690246582\n",
      "epoch: 5 step: 7, loss is 1.55122709274292\n",
      "epoch: 5 step: 8, loss is 1.351179838180542\n",
      "epoch: 5 step: 9, loss is 1.3640707731246948\n",
      "epoch: 5 step: 10, loss is 1.55759859085083\n",
      "epoch: 6 step: 1, loss is 1.4584338665008545\n",
      "epoch: 6 step: 2, loss is 1.4856622219085693\n",
      "epoch: 6 step: 3, loss is 1.4744184017181396\n",
      "epoch: 6 step: 4, loss is 1.3632487058639526\n",
      "epoch: 6 step: 5, loss is 1.559340000152588\n",
      "epoch: 6 step: 6, loss is 1.2030541896820068\n",
      "epoch: 6 step: 7, loss is 1.2690327167510986\n",
      "epoch: 6 step: 8, loss is 1.276416301727295\n",
      "epoch: 6 step: 9, loss is 1.1485283374786377\n",
      "epoch: 6 step: 10, loss is 0.9054062962532043\n",
      "epoch: 7 step: 1, loss is 0.9917359352111816\n",
      "epoch: 7 step: 2, loss is 1.1944825649261475\n",
      "epoch: 7 step: 3, loss is 0.9158105850219727\n",
      "epoch: 7 step: 4, loss is 1.0625863075256348\n",
      "epoch: 7 step: 5, loss is 0.9926900863647461\n",
      "epoch: 7 step: 6, loss is 1.1060625314712524\n",
      "epoch: 7 step: 7, loss is 1.0976598262786865\n",
      "epoch: 7 step: 8, loss is 0.9887036085128784\n",
      "epoch: 7 step: 9, loss is 0.999492883682251\n",
      "epoch: 7 step: 10, loss is 1.2357714176177979\n",
      "epoch: 8 step: 1, loss is 0.9345839023590088\n",
      "epoch: 8 step: 2, loss is 0.8632704019546509\n",
      "epoch: 8 step: 3, loss is 0.8248612880706787\n",
      "epoch: 8 step: 4, loss is 0.9604402184486389\n",
      "epoch: 8 step: 5, loss is 0.7742559909820557\n",
      "epoch: 8 step: 6, loss is 0.7479603290557861\n",
      "epoch: 8 step: 7, loss is 0.8755627274513245\n",
      "epoch: 8 step: 8, loss is 0.8582622408866882\n",
      "epoch: 8 step: 9, loss is 1.0483136177062988\n",
      "epoch: 8 step: 10, loss is 0.9775874614715576\n",
      "epoch: 9 step: 1, loss is 0.6342250108718872\n",
      "epoch: 9 step: 2, loss is 0.9106916785240173\n",
      "epoch: 9 step: 3, loss is 0.7162368297576904\n",
      "epoch: 9 step: 4, loss is 0.8801517486572266\n",
      "epoch: 9 step: 5, loss is 0.8700311183929443\n",
      "epoch: 9 step: 6, loss is 0.7335809469223022\n",
      "epoch: 9 step: 7, loss is 0.9477806091308594\n",
      "epoch: 9 step: 8, loss is 0.7734869718551636\n",
      "epoch: 9 step: 9, loss is 0.859015703201294\n",
      "epoch: 9 step: 10, loss is 0.8797844648361206\n",
      "epoch: 10 step: 1, loss is 0.8532097339630127\n",
      "epoch: 10 step: 2, loss is 0.7841359376907349\n",
      "epoch: 10 step: 3, loss is 0.6408644318580627\n",
      "epoch: 10 step: 4, loss is 0.9368440508842468\n",
      "epoch: 10 step: 5, loss is 0.9731941223144531\n",
      "epoch: 10 step: 6, loss is 0.8135749101638794\n",
      "epoch: 10 step: 7, loss is 0.7338972091674805\n",
      "epoch: 10 step: 8, loss is 0.8542121648788452\n",
      "epoch: 10 step: 9, loss is 0.7422550916671753\n",
      "epoch: 10 step: 10, loss is 0.7476415038108826\n"
     ]
    }
   ],
   "source": [
    "ds_train = create_multilabel_dataset(num_data=160)\n",
    "net = LinearNet()\n",
    "# 定义多标签损失函数\n",
    "loss = MAELossForMultiLabel()\n",
    "# 定义损失网络，连接前向网络和多标签损失函数\n",
    "loss_net = CustomWithLossCell(net, loss)\n",
    "# 定义优化器\n",
    "opt = nn.Momentum(net.trainable_params(), learning_rate=0.005, momentum=0.9)\n",
    "# 定义Model，多标签场景下Model无需指定损失函数\n",
    "model = ms.train.Model(network=loss_net, optimizer=opt)\n",
    "\n",
    "model.train(epoch=10, train_dataset=ds_train, callbacks=[LossMonitor(1)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7、模型预测\n",
    "使用模型进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:[[-1.31870369]]\n",
      "predict result:[[[-0.08267879]]]\n",
      "true result1:[[0.36259261]]\n",
      "true result2:[[0.36259261]]\n"
     ]
    }
   ],
   "source": [
    "from mindspore.train import Model\n",
    "from mindspore import Tensor\n",
    "\n",
    "model_predict = Model(net,loss_net,opt,metrics={\"loss\"})\n",
    "# 生成测试数据\n",
    "w=2.0\n",
    "b=3.0\n",
    "x = np.random.uniform(-10.0, 10.0, (1,1))\n",
    "x1 = np.array([x]).astype(np.float32)\n",
    "# 定义第一个标签\n",
    "true_result1 = x * w + b      \n",
    "# 定义第二个标签\n",
    "true_result2 = x * w + b            \n",
    "print('data:' + '%s'%x)\n",
    "# 模型测试\n",
    "test_result = model_predict.predict(Tensor(x1))\n",
    "print('predict result:' + '%s'%test_result)\n",
    "print('true result1:' + '%s'%true_result1)\n",
    "print('true result2:' + '%s'%true_result2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
