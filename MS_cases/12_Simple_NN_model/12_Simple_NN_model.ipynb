{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71079dcd-12b9-481a-9540-dc4f8ab319f5",
   "metadata": {},
   "source": [
    "# 使用MindSpore训练一个简单网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3623222-4e9c-4d31-b699-be3a2ebf3dbd",
   "metadata": {},
   "source": [
    "本节通过MindSpore的API快速实现一个简单的神经网络模型，使用MNIST数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cdfca5",
   "metadata": {},
   "source": [
    "## 1、实验目的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c94bed8",
   "metadata": {},
   "source": [
    "* 学会手写数字图像的数据载入及处理。\n",
    "* 掌握搭建全连接神经网络。\n",
    "* 掌握分类任务的训练流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e174a8",
   "metadata": {},
   "source": [
    "## 2、全连接神经网络原理介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b18e222",
   "metadata": {},
   "source": [
    "全连接神经网络，也可称为稠密连接网络，是一种多层的感知机结构，每一层的每一个节点都与上下层节点全部连接，这就是”全连接“的由来。整个全连接神经网络分为输入层，隐藏层和输出层，其中隐藏层可以更好的分离数据的特征，但是过多的隐藏层会导致过拟合问题。\n",
    "\n",
    "在模型训练过程中包含前向传播，反向传播，和模型更新步骤。\n",
    "\n",
    "其中，当前馈神经网络接收输入$x$并产生输出$\\hat y$时，信息通过网络向前流动。输入$x$提供初始信息，经过每一层的隐藏单元最终生成输出$\\hat y$，称为前向传播。此计算过程等同于线性回归计算，即给每一个输入向量x分配权值，计算出一个结果向量$\\hat y$。同时，为了使神经网络具有非线性特点，引入激活函数来处理线性变换得到的数值。对于单个神经元来讲：\n",
    "- 线性变换（加权和偏置）：$\\hat y=w^Tx+b$\n",
    "- 非线性变换（激活函数）：例如$\\delta(x)=\\frac{1}{1+e^{-x}}$\n",
    "\n",
    "前向传播可以持续向前指导产生标量成本函数，成本函数的信息通过网络向后流动，计算梯度优化网络，称为反向传播。反向传播在模型训练时通常被划分为梯度计算和参数优化两个部分。由于网络模型中可以定义多个隐藏层，需要递归的使用链式法则来实现反向传播。<br>\n",
    "\n",
    "全连接神经网络图示：\n",
    "![](./image/img2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575a9654",
   "metadata": {},
   "source": [
    "## 3、实验环境\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de2caaba",
   "metadata": {},
   "source": [
    "在动手进行实践之前，需要注意以下几点：\n",
    "* 确保实验环境正确安装，包括安装MindSpore。安装过程：首先登录[MindSpore官网安装页面](https://www.mindspore.cn/install)，根据安装指南下载安装包及查询相关文档。同时，官网环境安装也可以按下表说明找到对应环境搭建文档链接，根据环境搭建手册配置对应的实验环境。\n",
    "* 推荐使用交互式的计算环境Jupyter Notebook，其交互性强，易于可视化，适合频繁修改的数据分析实验环境。\n",
    "* 实验也可以在华为云一站式的AI开发平台ModelArts上完成。\n",
    "* 推荐实验环境：MindSpore版本=MindSpore 2.0；Python环境=3.7\n",
    "\n",
    "\n",
    "|  硬件平台 |  操作系统  | 软件环境 | 开发环境 | 环境搭建链接 |\n",
    "| :-----:| :----: | :----: |:----:   |:----:   |\n",
    "| CPU | Windows-x64 | MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.1节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| GPU CUDA 10.1|Linux-x86_64| MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.2节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| Ascend 910  | Linux-x86_64| MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第四章](./MindSpore环境搭建实验手册.docx)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bc484d-9fd8-4104-a42c-d12e6c0ead53",
   "metadata": {},
   "source": [
    "## 4、数据处理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e0654e",
   "metadata": {},
   "source": [
    "### 4.1 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe710989",
   "metadata": {},
   "source": [
    "MNIST数据集是机器学习领域中经典的数据集，由60,000个训练样本和10,000个测试样本组成，每个样本是28\\*28像素的灰度手写数字图片，共10类（0-9）。整个数据集约为50M。\n",
    "\n",
    "下载的数据集文件的目录结构如下：\n",
    "\n",
    "```text\n",
    "./MNIST_Data\n",
    "├── test\n",
    "│   ├── t10k-images-idx3-ubyte\n",
    "│   └── t10k-labels-idx1-ubyte\n",
    "└── train\n",
    "    ├── train-images-idx3-ubyte\n",
    "    └── train-labels-idx1-ubyte\n",
    "```\n",
    "MNIST示例\n",
    "\n",
    "![](./image/img1.png)\n",
    "\n",
    "MindSpore提供基于Pipeline的数据引擎，通过数据集（Dataset）和数据变换（Transforms）实现高效的数据预处理。在本教程中，我们使用Mnist数据集，自动下载完成后，使用mindspore.dataset提供的数据变换进行预处理。\n",
    "\n",
    "\n",
    "\n",
    ">此处的示例代码依赖download，可使用命令pip install download安装。如本文档以Notebook运行时，完成安装后需要重启kernel才能执行后续代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56c1cd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/MNIST_Data.zip (10.3 MB)\n",
      "\n",
      "file_sizes: 100%|██████████████████████████| 10.8M/10.8M [00:05<00:00, 1.84MB/s]\n",
      "Extracting zip file...\n",
      "Successfully downloaded / unzipped to ./\n"
     ]
    }
   ],
   "source": [
    "# 从开放数据集中下载MNIST数据集\n",
    "from download import download\n",
    "\n",
    "url = \"https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/\" \\\n",
    "      \"notebook/datasets/MNIST_Data.zip\"\n",
    "path = download(url, \"./\", kind=\"zip\", replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1130d57c",
   "metadata": {},
   "source": [
    "### 4.2 数据加载"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4f2895",
   "metadata": {},
   "source": [
    "导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fed87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MindSpore库\n",
    "import mindspore\n",
    "# 神经网络模块\n",
    "from mindspore import nn\n",
    "# 常见算子操作\n",
    "from mindspore import ops\n",
    "# 图像增强模块\n",
    "from mindspore.dataset import vision\n",
    "# 通用数据增强\n",
    "from mindspore.dataset import transforms\n",
    "# 读取和解析Manifest数据文件构建数据集\n",
    "from mindspore.dataset import MnistDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8613094d",
   "metadata": {},
   "source": [
    "设置超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "502d7b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE= 64       # batch的大小\n",
    "LEARNING_RATE = 1e-2 # 学习率\n",
    "EPOCH = 3            # 迭代次数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227881f9-8e48-475b-9fb5-e41ac8355cee",
   "metadata": {},
   "source": [
    "数据下载完成后，获得数据集对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae75ed41-d049-4ffb-bfa0-c33341f0a97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MnistDataset('MNIST_Data/train')\n",
    "test_dataset = MnistDataset('MNIST_Data/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209ddf94-bf43-4743-b70b-dac93a47b647",
   "metadata": {},
   "source": [
    "MindSpore的dataset使用数据处理流水线（Data Processing Pipeline），需指定map、batch、shuffle等操作。这里我们使用map对图像数据及标签进行变换处理，然后将处理好的数据集打包为大小为64的batch。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beaf6a3c-948e-474f-88d5-9b21dafdfeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapipe(dataset, batch_size):\n",
    "    image_transforms = [\n",
    "        # 基于给定的缩放和平移因子调整图像的像素大小。输出图像的像素大小为：output = image * rescale + shift。\n",
    "        # 此处rescale取1.0 / 255.0，shift取0\n",
    "        vision.Rescale(1.0 / 255.0, 0),\n",
    "        # 正则化 均值为0.1307，标准差为0.3081（查自官网）\n",
    "        vision.Normalize(mean=(0.1307,), std=(0.3081,)),\n",
    "        # 将输入图像的shape从 <H, W, C> 转换为 <C, H, W>\n",
    "        vision.HWC2CHW()\n",
    "    ]\n",
    "    # 将输入的Tensor转换为指定的数据类型。\n",
    "    label_transform = transforms.TypeCast(mindspore.int32)\n",
    "\n",
    "    # map给定一组数据增强列表，按顺序将数据增强作用在数据集对象上。\n",
    "    dataset = dataset.map(image_transforms, 'image')\n",
    "    dataset = dataset.map(label_transform, 'label')\n",
    "    # 将数据集中连续 batch_size 条数据组合为一个批数据\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "# 对数据集进行transfrom和batch\n",
    "train_dataset = datapipe(train_dataset, BATCH_SIZE)\n",
    "test_dataset = datapipe(test_dataset, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22587305-301b-4117-acc3-e026fb044eb0",
   "metadata": {},
   "source": [
    "## 5、模型构建\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae0bf81",
   "metadata": {},
   "source": [
    "mindspore.nn类是构建所有网络的基类，也是网络的基本单元。当用户需要自定义网络时，可以继承nn.Cell类，并重写__init__方法和construct方法。__init__包含所有网络层的定义，construct中包含数据（Tensor）的变换过程（即计算图的构造过程）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f79256fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network<\n",
      "  (flatten): Flatten<>\n",
      "  (dense_relu_sequential): SequentialCell<\n",
      "    (0): Dense<input_channels=784, output_channels=512, has_bias=True>\n",
      "    (1): ReLU<>\n",
      "    (2): Dense<input_channels=512, output_channels=512, has_bias=True>\n",
      "    (3): ReLU<>\n",
      "    (4): Dense<input_channels=512, output_channels=10, has_bias=True>\n",
      "    >\n",
      "  >\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "# MindSpore 中提供用户通过继承 nn.Cell 来方便用户创建和执行自己的网络\n",
    "class Network(nn.Cell): \n",
    "    # 自定义的网络中，需要在__init__构造函数中申明各个层的定义\n",
    "    def __init__(self): \n",
    "         # 继承父类nn.cell的__init__方法\n",
    "        super().__init__()         \n",
    "        # nn.Flatten为输入展成平图层，即去掉那些空的维度\n",
    "        self.flatten = nn.Flatten()\n",
    "        # 使用SequentialCell对网络进行管理\n",
    "        self.dense_relu_sequential = nn.SequentialCell(\n",
    "            # nn.Dense为致密连接层，它的第一个参数为输入层的维度，第二个参数为输出的维度，\n",
    "            # 第三个参数为神经网络可训练参数W权重矩阵的初始化方式，默认为normal\n",
    "            # nn.ReLU()非线性激活函数，它往往比论文中的sigmoid激活函数具有更好的效益\n",
    "            nn.Dense(28 * 28, 512), # 致密连接层 输入28*28 输出512\n",
    "            nn.ReLU(),              # ReLU层\n",
    "            nn.Dense(512, 512),     # 致密连接层 输入512 输出512\n",
    "            nn.ReLU(),              # ReLu层\n",
    "            nn.Dense(512, 10)       # 致密连接层 输入512 输出10\n",
    "        )\n",
    "    # 在construct中实现层之间的连接关系，完成神经网络的前向构造\n",
    "    def construct(self, x):\n",
    "         #调用init中定义的self.flatten()方法 \n",
    "        x = self.flatten(x)\n",
    "        #调用init中的self.dense_relu_sequential()方法\n",
    "        logits = self.dense_relu_sequential(x)\n",
    "        # 返回模型\n",
    "        return logits\n",
    "model = Network()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d289f4c4-ecf5-4c0f-aec1-d2bb1bdfce24",
   "metadata": {},
   "source": [
    "## 6、模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b878b26d-33db-4b85-8e0b-3f357902221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化损失函数和优化器\n",
    "# 计算预测值和目标值之间的交叉熵损失\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "#构建一个Optimizer对象，能够保持当前参数状态并基于计算得到的梯度进行参数更新 此处使用随机梯度下降算法\n",
    "optimizer = nn.SGD(model.trainable_params(), learning_rate=LEARNING_RATE) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a66e3d-0fb6-4329-818c-692b216db6a1",
   "metadata": {},
   "source": [
    "在模型训练中，一个完整的训练过程（step）需要实现以下三步：\n",
    "1. 正向计算：模型预测结果（logits），并与正确标签（label）求预测损失（loss）。\n",
    "2. 反向传播：利用自动微分机制，自动求模型参数（parameters）对于loss的梯度（gradients）。\n",
    "3. 参数优化：将梯度更新到参数上。\n",
    "\n",
    "MindSpore使用函数式自动微分机制，因此针对上述步骤需要实现：\n",
    "1. 正向计算函数定义。\n",
    "2. 通过函数变换获得梯度计算函数。\n",
    "3. 训练函数定义，执行正向计算、反向传播和参数优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ced15eee-8024-4f52-8639-0a805bc2d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, loss_fn, optimizer):\n",
    "    # 定义 forward 函数\n",
    "    def forward_fn(data, label):\n",
    "        # 将数据载入模型\n",
    "        logits = model(data)\n",
    "        # 根据模型训练获取损失函数值\n",
    "        loss = loss_fn(logits, label)\n",
    "        return loss, logits\n",
    "    # 调用梯度函数，value_and_grad()为生成求导函数，用于计算给定函数的正向计算结果和梯度\n",
    "    grad_fn = ops.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=True)\n",
    "    # 定义一步训练的函数\n",
    "    def train_step(data, label):\n",
    "        # 计算梯度，记录变量是怎么来的\n",
    "        (loss, _), grads = grad_fn(data, label)\n",
    "        # 获得损失 depend用来处理操作间的依赖关系\n",
    "        loss = ops.depend(loss, optimizer(grads))\n",
    "        return loss\n",
    "    size = dataset.get_dataset_size()\n",
    "    model.set_train()\n",
    "    for batch, (data, label) in enumerate(dataset.create_tuple_iterator()):\n",
    "        # 批量训练获得损失值\n",
    "        loss = train_step(data, label)\n",
    "        # 当完成所有数据样本的训练\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.asnumpy(), batch\n",
    "            print(f\"loss: {loss:>7f}  [{current:>3d}/{size:>3d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d65fceb-1b8e-4642-9166-f3c1e4810b34",
   "metadata": {},
   "source": [
    "除训练外，我们定义测试函数，用来评估模型的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fce8386e-a08d-4c24-be6f-2d16c4d5ab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataset, loss_fn):\n",
    "    num_batches = dataset.get_dataset_size()\n",
    "    model.set_train(False)\n",
    "    total, test_loss, correct = 0, 0, 0\n",
    "    for data, label in dataset.create_tuple_iterator(): # 遍历所有测试样本数据\n",
    "        pred = model(data)                              # 根据已训练模型获取预测值\n",
    "        total += len(data)                              # 统计样本数\n",
    "        test_loss += loss_fn(pred, label).asnumpy()     # 统计样本损失值\n",
    "        correct += (pred.argmax(1) == label).asnumpy().sum()# 统计预测正确的样本个数\n",
    "    test_loss /= num_batches                              # 求得平均损失\n",
    "    correct /= total                                      # 计算accuracy\n",
    "    print(f\"Test: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f3adb8-b693-4a27-ae7c-75da37576cb2",
   "metadata": {},
   "source": [
    "训练过程需多次迭代数据集，一次完整的迭代称为一轮（epoch）。在每一轮，遍历训练集进行训练，结束后使用测试集进行预测。打印每一轮的loss值和预测准确率（Accuracy），可以看到loss在不断下降，Accuracy在不断提高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6057cc1d-a64e-48ea-8892-8417b323e595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.302374  [  0/938]\n",
      "loss: 2.289070  [100/938]\n",
      "loss: 2.258706  [200/938]\n",
      "loss: 2.162465  [300/938]\n",
      "loss: 1.990072  [400/938]\n",
      "loss: 1.491828  [500/938]\n",
      "loss: 1.056657  [600/938]\n",
      "loss: 0.791395  [700/938]\n",
      "loss: 0.747034  [800/938]\n",
      "loss: 0.758159  [900/938]\n",
      "Test: \n",
      " Accuracy: 85.5%, Avg loss: 0.518855 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.534654  [  0/938]\n",
      "loss: 0.645424  [100/938]\n",
      "loss: 0.438396  [200/938]\n",
      "loss: 0.397434  [300/938]\n",
      "loss: 0.506358  [400/938]\n",
      "loss: 0.280990  [500/938]\n",
      "loss: 0.275507  [600/938]\n",
      "loss: 0.341971  [700/938]\n",
      "loss: 0.279664  [800/938]\n",
      "loss: 0.425316  [900/938]\n",
      "Test: \n",
      " Accuracy: 90.0%, Avg loss: 0.336232 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.431660  [  0/938]\n",
      "loss: 0.299660  [100/938]\n",
      "loss: 0.493997  [200/938]\n",
      "loss: 0.144846  [300/938]\n",
      "loss: 0.149156  [400/938]\n",
      "loss: 0.377380  [500/938]\n",
      "loss: 0.335227  [600/938]\n",
      "loss: 0.215083  [700/938]\n",
      "loss: 0.125211  [800/938]\n",
      "loss: 0.312093  [900/938]\n",
      "Test: \n",
      " Accuracy: 91.7%, Avg loss: 0.284121 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(EPOCH):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(model, train_dataset, loss_fn, optimizer)      # 训练模型\n",
    "    test(model, test_dataset, loss_fn)                   # 测试模型\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d770d09d",
   "metadata": {},
   "source": [
    "## 7、模型预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413d45e1-b68a-4e63-9b66-2952fc2813e6",
   "metadata": {},
   "source": [
    "###  保存模型\n",
    "模型训练完成后，需要将其参数进行保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b40f9637-101d-40c7-8d13-93c6ec4f8dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model to model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# 保存checkpoint时的配置策略\n",
    "mindspore.save_checkpoint(model, \"model.ckpt\")\n",
    "print(\"Saved Model to model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd96877d-a1ca-4e74-9534-a2797fd16526",
   "metadata": {},
   "source": [
    "### 加载模型\n",
    "加载保存的权重分为两步：\n",
    "1. 重新实例化模型对象，构造模型。\n",
    "2. 加载模型参数，并将其加载至模型上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81c99e31-eb2a-4a44-871f-764eb2aefb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 实例化一个随机初始化的模型 \n",
    "model = Network()\n",
    "# 加载检查点，加载参数到模型 \n",
    "param_dict = mindspore.load_checkpoint(\"model.ckpt\")\n",
    "param_not_load = mindspore.load_param_into_net(model, param_dict)\n",
    "print(param_not_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bd137e-cb77-4f96-94d6-81d3c1919bc8",
   "metadata": {},
   "source": [
    ">param_not_load是未被加载的参数列表，为空时代表所有参数均加载成功。\n",
    "\n",
    "加载后的模型可以直接用于预测推理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95dce13a-eeab-414f-980c-1326f12b2d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"[8 3 2 1 0 1 6 7 2 2]\", Actual: \"[8 3 2 1 0 1 6 7 2 2]\"\n"
     ]
    }
   ],
   "source": [
    "model.set_train(False)\n",
    "for data, label in test_dataset:\n",
    "    pred = model(data)\n",
    "    predicted = pred.argmax(1)\n",
    "    print(f'Predicted: \"{predicted[:10]}\", Actual: \"{label[:10]}\"')\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "494deeb4eea7fb63b62f74ba02ace728543e0003fbb675bfec79f4f4980c3f04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
