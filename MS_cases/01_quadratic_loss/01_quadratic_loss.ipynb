{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于MindSpore构造平方损失函数 \n",
    "本实验主要介绍使用MindSpore构造平方损失函数，利用自定义的数据集和线性模型验证。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1、实验目的\n",
    "- 掌握平方损失函数的原理\n",
    "- 掌握如何使用MindSpore构造平方损失函数\n",
    "- 了解如何使用MindSpore进行模型的训练和验证"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2、 平方损失函数原理介绍\n",
    "平方损失函数(Square Loss)用于测量机器学习模型的输出与实际结果之间的距离，平方损失函数一般不用于分类问题。。假设$y_i$是真实值，$\\hat{y}_i$是预测值，则平方损失函数$J(\\theta)$的公式如下：\n",
    "$$J(\\theta)=\\frac{1}{2}\\sum^{n}_{i=0}(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "\n",
    "本实验中平方损失函数通过重写L1Loss实现，L1范数是指向量中各个元素绝对值之和，对于向量$x=[x_1,x_2,…,x_n ]^T$，其L1范数为：\n",
    "$$‖x‖_1=|x_1|+|x_2|+⋯+|x_n|$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3、 实验环境\n",
    "在动手进行实践之前，需要注意以下几点：\n",
    "* 确保实验环境正确安装，包括安装MindSpore。安装过程：首先登录[MindSpore官网安装页面](https://www.mindspore.cn/install)，根据安装指南下载安装包及查询相关文档。同时，官网环境安装也可以按下表说明找到对应环境搭建文档链接，根据环境搭建手册配置对应的实验环境。\n",
    "* 推荐使用交互式的计算环境Jupyter Notebook，其交互性强，易于可视化，适合频繁修改的数据分析实验环境。\n",
    "* 实验也可以在华为云一站式的AI开发平台ModelArts上完成。\n",
    "* 推荐实验环境：MindSpore版本=MindSpore 2.0；Python环境=3.7\n",
    "\n",
    "\n",
    "|  硬件平台 |  操作系统  | 软件环境 | 开发环境 | 环境搭建链接 |\n",
    "| :-----:| :----: | :----: |:----:   |:----:   |\n",
    "| CPU | Windows-x64 | MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.1节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| GPU CUDA 10.1|Linux-x86_64| MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.2节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| Ascend 910  | Linux-x86_64| MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第四章](./MindSpore环境搭建实验手册.docx)|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4、数据处理\n",
    "## 4.1 数据准备\n",
    "这是一个自定义的简单数据集，包括两类数据'xy'和'z'，'xy'由x和y两列数据组成，它们都服从[-1,1]的均匀分布，'z'由它们生成，公式如下：\n",
    "$$z=a*x^2+b*y^3+c+noise$$\n",
    "其中，a、b、c是自定义的超参数，noise是服从(0,0.03)的正态分布。\n",
    "数据集大小为160，分为10个批次，每个批次增强10倍。数据的形式如下："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$xy=[[[ 7.56207947e-03, -3.43424603e-02]],\\\\\n",
    " [[ 4.21533167e-01, -4.53344226e-01]],\\\\\n",
    " [[ 1.59027276e-03,  8.72432720e-05]],\\\\\n",
    " ...\\\\\n",
    " [[ 3.67112603e-04, -2.49217793e-01]],\\\\\n",
    " [[ 1.86624035e-01, -1.43198028e-01]],\\\\\n",
    " [[ 7.65149057e-01, -1.37545183e-01]]]$$\n",
    " \n",
    "$$z=\n",
    "[[ 4.91964149e+00],\\\\\n",
    " [ 4.45919466e+00],\\\\\n",
    " [ 5.02036238e+00],\\\\\n",
    " ...\\\\\n",
    " [ 4.26575947e+00],\\\\\n",
    " [ 4.87499523e+00],\\\\\n",
    " [ 6.14354038e+00]]$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 数据加载\n",
    "这里进行自定义数据集的生成和增强操作，首先`get_data`函数根据公式获取数据，然后在`create_dataset`函数生成数据集，并进行数据增强和处理操作：\n",
    "- 定义进行数据增强和处理所需要的一些参数。\n",
    "- 根据参数，生成对应的数据增强操作。\n",
    "- 对生成的数据集进行处理。\n",
    "- 对处理好的数据进行样例展示。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(7328:17100,MainProcess):2023-02-25-02:32:53.608.675 [mindspore\\dataset\\engine\\datasets_user_defined.py:657] Python multiprocessing is not supported on Windows platform.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mindspore import dataset as ds\n",
    "\n",
    "# 获取数据\n",
    "def get_data(num, a=2.0, b=3.0, c=5.0):\n",
    "    \n",
    "    for _ in range(num):\n",
    "        # 均匀分布\n",
    "        x = np.random.uniform(-1.0, 1.0)\n",
    "        y = np.random.uniform(-1.0, 1.0)\n",
    "        # 添加噪声\n",
    "        noise = np.random.normal(0, 0.03)\n",
    "        z = a * x ** 2 + b * y ** 3 + c + noise\n",
    "        yield np.array([[x**2], [y**3]],dtype=np.float32).reshape(1,2), np.array([z]).astype(np.float32)\n",
    "\n",
    "# 生成数据集并增强\n",
    "def create_dataset(num_data, batch_size=16, repeat_size=1):\n",
    "    # 生成数据集\n",
    "    input_data = ds.GeneratorDataset(list(get_data(num_data)), column_names=['xy','z'])\n",
    "    # 划分批次\n",
    "    input_data = input_data.batch(batch_size)\n",
    "    # 增强数据集\n",
    "    input_data = input_data.repeat(repeat_size)\n",
    "    return input_data\n",
    " \n",
    "data_number = 160       # 数据集大小\n",
    "batch_number = 10       # 批量大小  \n",
    "repeat_number = 10      # 增强次数\n",
    "\n",
    "# 训练集\n",
    "ds_train = create_dataset(data_number, batch_size=batch_number, repeat_size=repeat_number)\n",
    "# 测试集\n",
    "ds_test = create_dataset(data_number, batch_size=batch_number, repeat_size=repeat_number)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  5、模型构建\n",
    "\n",
    "模型的构建包括如下部分：\n",
    "- 导入库和函数\n",
    "- 定义线性模型\n",
    "- 重写损失函数\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入所需库和函数\n",
    "\n",
    "首先导入需要的Python库。\n",
    "\n",
    "然后导入相关的MindSpore模块，详细的MindSpore的模块说明，可以在MindSpore API页面中搜索查询。\n",
    "\n",
    "可以通过context.set_context来配置运行需要的信息，譬如运行模式、后端信息、硬件等信息。导入context模块，配置运行需要的信息。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间处理模块\n",
    "import time\n",
    "# 科学计算库\n",
    "import numpy as np\n",
    "# MindSpore库\n",
    "import mindspore as ms\n",
    "# 常见算子操作\n",
    "import mindspore.ops as ops\n",
    "# 数据集处理模块\n",
    "from mindspore import dataset as ds\n",
    "# 神经网络模块，张量\n",
    "from mindspore import nn, Tensor\n",
    "# 模型训练设置\n",
    "from mindspore.train import Callback, LossMonitor, Model\n",
    "# L1型损失函数\n",
    "from mindspore.nn import L1Loss\n",
    "# MindSpore环境设置的0号种子\n",
    "ms.set_seed(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义一个简单的线性模型\n",
    "\n",
    "这里是线性网络的最简单实现，一个全连接层，公式如下：\n",
    "$$outputs=activation(X*kernel+bias)$$\n",
    "其中 X 是输入Tensor， activation 是激活函数， kernel 是一个权重矩阵，其数据类型与 X 相同， bias 是一个偏置向量，其数据类型与 X 相同（仅当has_bias为True时）。\n",
    "\n",
    "这里使用的是一个全连接层`mindspore.nn.Dense`，输入维度为2，输出维度为1，初始化权重为0.02，初始化偏置为0.02。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义线性模型\n",
    "class LinearNet(nn.Cell):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        # 全连接层\n",
    "        self.fc = nn.Dense(2, 1, 0.02, 0.02)\n",
    " \n",
    "    def construct(self, x):\n",
    "        # 前向传播\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看模型中参数维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param Shape is: 2\n",
      "Parameter (name=fc.weight, shape=(1, 2), dtype=Float32, requires_grad=True) [[0.02 0.02]]\n",
      "Parameter (name=fc.bias, shape=(1,), dtype=Float32, requires_grad=True) [0.02]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "net = LinearNet()\n",
    "model_params = net.trainable_params()\n",
    "\n",
    "# 显示模型的参数及其大小\n",
    "print ('Param Shape is: {}'.format(len(model_params)))\n",
    "for net_param in net.trainable_params():\n",
    "    print(net_param, net_param.asnumpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重写L1型损失函数，实现自定义的平方损失函数\n",
    "\n",
    "`L1Loss`用于计算预测值和目标值之间的平均绝对误差。而平方损失函数只需要对L1Loss进行平方操作，并乘上0.5。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义平方损失函数\n",
    "class quadratic_loss(L1Loss):\n",
    "    def __init__(self, reduction=\"mean\"):\n",
    "        super(quadratic_loss, self).__init__(reduction)\n",
    " \n",
    "    def construct(self, base, target):\n",
    "        # 平方损失函数\n",
    "        x = 0.5 * ops.square(base - target)\n",
    "        return self.get_loss(x)\n",
    "\n",
    "user_loss = quadratic_loss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6、模型训练\n",
    "\n",
    "完成数据预处理、网络定义、损失函数之后，选择优化器，开始模型训练。模型训练包含1层迭代，数据集按分组从训练集中抽取数据，输入网络计算得到损失函数。\n",
    "\n",
    "因为本实验只是计算平方损失函数值，不涉及梯度计算和反向传播，所以优化器的选择并不重要。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 10, loss is 14.196735382080078\n",
      "epoch: 1 step: 20, loss is 6.716091156005859\n",
      "epoch: 1 step: 30, loss is 4.461669445037842\n",
      "epoch: 1 step: 40, loss is 2.9822726249694824\n",
      "epoch: 1 step: 50, loss is 1.8455755710601807\n",
      "epoch: 1 step: 60, loss is 1.0462146997451782\n",
      "epoch: 1 step: 70, loss is 0.7596532702445984\n",
      "epoch: 1 step: 80, loss is 1.0583897829055786\n",
      "epoch: 1 step: 90, loss is 1.3813812732696533\n",
      "epoch: 1 step: 100, loss is 0.9386886358261108\n",
      "epoch: 1 step: 110, loss is 0.7798466682434082\n",
      "epoch: 1 step: 120, loss is 0.9109617471694946\n",
      "epoch: 1 step: 130, loss is 1.8585299253463745\n",
      "epoch: 1 step: 140, loss is 0.8565757870674133\n",
      "epoch: 1 step: 150, loss is 1.2890172004699707\n",
      "epoch: 1 step: 160, loss is 0.4561425745487213\n",
      "Parameter (name=fc.weight, shape=(1, 2), dtype=Float32, requires_grad=True) [[1.4566594  0.19539458]]\n",
      "Parameter (name=fc.bias, shape=(1,), dtype=Float32, requires_grad=True) [5.1525297]\n",
      "The total time cost is: 41.54380178451538s\n"
     ]
    }
   ],
   "source": [
    "# 选择动量优化器\n",
    "optim = nn.Momentum(net.trainable_params(), learning_rate=0.01, momentum=0.6)\n",
    "# 使用Model接口将网络、损失函数和优化器关联起来\n",
    "model = Model(net, user_loss, optim)\n",
    " \n",
    "# 开始训练\n",
    "epoch = 1\n",
    "model.train(epoch, ds_train, callbacks=[LossMonitor(10)], dataset_sink_mode=True)\n",
    " \n",
    "# 显示模型参数\n",
    "for net_param in net.trainable_params():\n",
    "    print(net_param, net_param.asnumpy())\n",
    "\n",
    "# 显示训练时间\n",
    "print ('The total time cost is: {}s'.format(time.time() - start_time))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7、模型预测\n",
    "\n",
    "模型训练完成后，输入测试集进行模型预测，计算平方损失函数值。\n",
    "\n",
    "模型预测时不需要设置优化器，只需要设置网络、损失函数和评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "model = Model(net, loss_fn=user_loss, optimizer=None, metrics={'loss'})\n",
    "# 计算测试集的平方损失函数值\n",
    "pred_loss = model.eval(ds_test, dataset_sink_mode=False)\n",
    "print(f'prediction loss is {pred_loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d9fe059ab7d23d498f40a7052f43040c1b89b97bcd1b6ba6b66c3943ea2a584"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
