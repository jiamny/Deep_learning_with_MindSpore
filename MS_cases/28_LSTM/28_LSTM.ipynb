{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c93eafe7-7514-4e57-9af5-d3e30455a6b0",
   "metadata": {},
   "source": [
    "#  基于MindSpore实现LSTM算法 \n",
    "本实验基于MindSpore构建LSTM模型，使用SentimentNet实现情感分类,并训练和测试模型。\n",
    "## 1 实验目的\n",
    "1.通过实验了解LSTM算法\n",
    "\n",
    "2.基于MindSpore中实现LSTM算法\n",
    "## 2 LSTM算法原理介绍\n",
    "LSTM四个函数层与具体介绍如下：\n",
    "\n",
    "(1)第一个函数层：遗忘门\n",
    "    ![jupyter](./Figures/fig001.png)\n",
    " \n",
    "对于上一时刻LSTM中的单元状态，一些信息可能会随着时间的流逝而过时。为了不让过多记忆影响神经网络对现在输入的处理，我们应该选择性遗忘一些在之前单元状态中的分量——这个工作就交给了遗忘门。\n",
    "\n",
    "每一次输入一个新的输入，LSTM会先根据新的输入和上一时刻的输出决定遗忘之前的哪些记忆——输入和上一步的输出会整合为一个单独的向量，然后通过sigmoid神经层，最后点对点的乘在单元状态上。因为sigmoid 函数会将任意输入压缩到 (0,1) 的区间上，我们可以非常直觉的得出这个门的工作原理 —— 如果整合后的向量某个分量在通过sigmoid层后变为0，那么显然单元状态在对位相乘后对应的分量也会变成0，换句话说，遗忘了这个分量上的信息；如果某个分量通过sigmoid层后为1，单元状态会“保持完整记忆”。不同的sigmoid输出会带来不同信息的记忆与遗忘。通过这种方式，LSTM可以长期记忆重要信息，并且记忆可以随着输入进行动态调整。下面的公式可以用来描述遗忘门的计算，其中f_t就是sigmoid神经层的输出向量：\n",
    "\n",
    "$f_t=σ(W_f∙[h_(t-1),x_t ]+b_f)$\n",
    "\n",
    "（2）第二个、第三个函数层：记忆门\n",
    "记忆门是用来控制是否将在t时刻（现在）的数据并入单元状态中的控制单位。首先，用tanh函数层将现在的向量中的有效信息提取出来，然后使用sigmoid函数来控制这些记忆要放多少进入单元状态。这两者结合起来就可以做到：\n",
    "\n",
    " ![jupyter](./Figures/fig002.png)\n",
    " \n",
    "从当前输入中提取有效信息；对提取的有效信息做出筛选，为每个分量做出评级(0 ~ 1)，评级越高的最后会有越多的记忆进入单元状态。下面的公式可以分别表示这两个步骤在LSTM中的计算：\n",
    "\n",
    "$C_{t}^{'}=tanh⁡(W_c∙[h_{(t-1)},x_t ]+b_c)$\n",
    "\n",
    "$i_t=σ(W_i∙[h_{(t-1)},x_t ]+b_i)$\n",
    "\n",
    "（3）第四个函数层：输出门\n",
    "\n",
    "输出门就是LSTM单元用于计算当前时刻的输出值的神经层。输出层会先将当前输入值与上一时刻输出值整合后的向量用sigmoid函数提取其中的信息，然后，会将当前的单元状态通过tanh函数压缩映射到区间(-1, 1)中，将经过tanh函数处理后的单元状态与sigmoid函数处理后的单元状态，整合后的向量点对点的乘起来就可以得到LSTM在 t时刻的输出。\n",
    "\n",
    "LSTM模型是由时刻的输入词$X_{t}$ ，细胞状态$C_{t}$，临时细胞状态$\\widetilde{C_{t}} $，隐层状态$h_{t}$，遗忘门$f_{t}$，记忆门$i_{t}$，输出门$ o_{t}$组成。LSTM的计算过程可以概括为:通过对细胞状态中信息遗忘和记忆新的信息使得对后续时刻计算有用的信息得以传递，而无用的信息被丢弃，并在每个时间步都会输出隐层状态$h_{t}$ ，其中遗忘、记忆与输出由通过上个时刻的隐层状态$h_{t-1}$和当前输入$X_{t}$计算出来的遗忘门$f_{t}$，记忆门$ i_{t}$，输出门$o_{t}$来控制。\n",
    "\n",
    "LSTM总体框架图如下：\n",
    " ![jupyter](./Figures/fig003.png)\n",
    "\n",
    "\n",
    "## 3 实验环境\n",
    "### 实验环境要求\n",
    "在动手进行实践之前，需要注意以下几点：\n",
    "* 确保实验环境正确安装，包括安装MindSpore。安装过程：首先登录[MindSpore官网安装页面](https://www.mindspore.cn/install)，根据安装指南下载安装包及查询相关文档。同时，官网环境安装也可以按下表说明找到对应环境搭建文档链接，根据环境搭建手册配置对应的实验环境。\n",
    "* 推荐使用交互式的计算环境Jupyter Notebook，其交互性强，易于可视化，适合频繁修改的数据分析实验环境。\n",
    "* 实验也可以在华为云一站式的AI开发平台ModelArts上完成。\n",
    "* 推荐实验环境：MindSpore版本=MindSpore 2.0；Python环境=3.7\n",
    "\n",
    "\n",
    "|  硬件平台 |  操作系统  | 软件环境 | 开发环境 | 环境搭建链接 |\n",
    "| :-----:| :----: | :----: |:----:   |:----:   |\n",
    "| CPU | Windows-x64 | MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.1节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| GPU CUDA 10.1|Linux-x86_64| MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.2节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| Ascend 910  | Linux-x86_64| MindSpore2.0 Python3.7.5 | JupyterNotebook |[MindSpore环境搭建实验手册第四章](./MindSpore环境搭建实验手册.docx)|\n",
    "## 4 数据处理\n",
    "IMDB是一个与国内豆瓣比较类似的与电影相关的网站，而本次实验用到的数据集是这个网站中的一些用户评论。IMDB数据集共包含50000项影评文字，训练数据和测试数据各25000项，每一项影评文字都被标记为正面评价或负面评价，所以本实验可以看做一个二分类问题。IMDB数据集官网：[Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/)。\n",
    "\n",
    "方式一，从斯坦福大学官网下载aclImdb_v1.tar.gz并解压。\n",
    "\n",
    "方式二，从华为云OBS中下载aclImdb_v1.tar.gz并解压。\n",
    "\n",
    "同时，我们要下载GloVe文件，并在文件glove.6B.300d.txt开头处添加新的一行400000 300，即总共读取400000个单词，每个单词用300维度的词向量表示。 修改glove.6B.300.txt如下:\n",
    "\n",
    "400000 300\n",
    "\n",
    "the -0.071549 0.093459 0.023738 -0.090339 0.056123 0.32547…\n",
    "\n",
    "确定评价标准：\n",
    "作为典型的分类问题，情感分类的评价标准可以比照普通的分类问题处理。常见的精度（Accuracy）、精准度（Precision）、召回率（Recall）和F_beta分数都可以作为参考。\n",
    "\n",
    "精度（Accuracy）=分类正确的样本数目/总样本数目\n",
    "\n",
    "精准度（Precision）=真阳性样本数目/所有预测类别为阳性的样本数目\n",
    "\n",
    "召回率（Recall）=真阳性样本数目/所有真实类别为阳性的样本数目\n",
    "\n",
    "F1分数=(2∗Precision∗Recall)/(Precision+Recall)\n",
    "\n",
    "在IMDB这个数据集中，正负样本数差别不大，可以简单地用精度（accuracy）作为分类器的衡量标准。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4cc0ce-285a-40ac-8411-bc01f8a4a912",
   "metadata": {},
   "source": [
    "## 5 模型构建\n",
    "（1）导入Python库&模块并配置运行信息\n",
    "\n",
    "导入MindSpore模块和辅助模块。\n",
    "\n",
    "代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5861f722-131e-49e9-930b-aefc6cda3b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "from mindspore.train import Model\n",
    "from mindspore import context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a79e23-6cfc-4ee1-8a55-3cda136f4edc",
   "metadata": {},
   "source": [
    "(2）定义参数变量\n",
    "\n",
    "device_target：指定Ascend或CPU/GPU环境。\n",
    "pre_trained：预加载CheckPoint文件。\n",
    "preprocess：是否预处理数据集，默认为否。\n",
    "aclimdb_path：数据集存放路径。\n",
    "glove_path：GloVe文件存放路径。\n",
    "preprocess_path：预处理数据集的结果文件夹。\n",
    "ckpt_path：CheckPoint文件路径。   \n",
    "\n",
    "注意：若在GPU上训练需要更改 'device_target': \"CPU\"为 'device_target': \"GPU\"。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "824516b9-2656-4898-b288-65cbe8af6ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置参数变量\n",
    "from easydict import EasyDict as edict\n",
    "lstm_cfg = edict({\n",
    "    'num_classes': 2,\n",
    "    'learning_rate': 0.1,\n",
    "    'momentum': 0.9,\n",
    "    'num_epochs': 1,    \n",
    "    'batch_size': 128,\n",
    "    'embed_size': 300,\n",
    "    'num_hiddens': 100,\n",
    "    'num_layers': 2,\n",
    "    'bidirectional': True,\n",
    "    'save_checkpoint_steps': 390,\n",
    "    'keep_checkpoint_max': 10\n",
    "})\n",
    "args_train = edict({\n",
    "    'preprocess': 'true',\n",
    "    'aclimdb_path': \"./aclImdb\",\n",
    "    'glove_path': \"./glove\",\n",
    "    'preprocess_path': \"./preprocess\",\n",
    "    'ckpt_path': \"./\",\n",
    "    'pre_trained': None,\n",
    "    'device_target': \"CPU\",\n",
    "})\n",
    "args_test = edict({\n",
    "    'preprocess': 'false',\n",
    "    'aclimdb_path': \"./aclImdb\",\n",
    "    'glove_path': \"./glove\",\n",
    "    'preprocess_path': \"./preprocess\",\n",
    "    'ckpt_path': \"./lstm-1_195.ckpt\",\n",
    "    'pre_trained': None,\n",
    "    'device_target': \"CPU\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729e5e9d",
   "metadata": {},
   "source": [
    "（3）数据的读取与处理\n",
    "\n",
    "按照下面的流程解析原始数据集，获得features与labels：sentence->tokenized->encoded->padding->features。\n",
    "\n",
    "定义convert_to_mindrecord函数将数据集格式转换为MindRecord格式，便于MindSpore读取。\n",
    "对文本数据集进行处理，包括编码、分词、对齐、处理GloVe原始数据，使之能够适应网络结构。\n",
    "\n",
    "定义convert_to_mindrecord函数将数据集格式转换为MindRecord格式，便于MindSpore读取。\n",
    "\n",
    "转换成功后会在`preprocess`目录下生成MindRecord文件，通常该操作在数据集不变的情况下，无需每次训练都执行，此时查看`preprocess`文件目录结构。\n",
    "\n",
    "```text\n",
    "preprocess\n",
    "├── aclImdb_test.mindrecord0\n",
    "├── aclImdb_test.mindrecord0.db\n",
    "├── aclImdb_test.mindrecord1\n",
    "├── aclImdb_test.mindrecord1.db\n",
    "├── aclImdb_test.mindrecord2\n",
    "├── aclImdb_test.mindrecord2.db\n",
    "├── aclImdb_test.mindrecord3\n",
    "├── aclImdb_test.mindrecord3.db\n",
    "├── aclImdb_train.mindrecord0\n",
    "├── aclImdb_train.mindrecord0.db\n",
    "├── aclImdb_train.mindrecord1\n",
    "├── aclImdb_train.mindrecord1.db\n",
    "├── aclImdb_train.mindrecord2\n",
    "├── aclImdb_train.mindrecord2.db\n",
    "├── aclImdb_train.mindrecord3\n",
    "├── aclImdb_train.mindrecord3.db\n",
    "└── weight.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19e15e70-046c-4ac6-9c22-c1aa4f7bb6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import gensim\n",
    "class ImdbParser():\n",
    "    def __init__(self, imdb_path, glove_path, embed_size=300):\n",
    "        self.__segs = ['train', 'test']\n",
    "        self.__label_dic = {'pos': 1, 'neg': 0}\n",
    "        self.__imdb_path = imdb_path\n",
    "        self.__glove_dim = embed_size\n",
    "        self.__glove_file = os.path.join(glove_path, 'glove.6B.' + str(self.__glove_dim) + 'd.txt')\n",
    "        self.__imdb_datas = {}\n",
    "        self.__features = {}\n",
    "        self.__labels = {}\n",
    "        self.__vacab = {}\n",
    "        self.__word2idx = {}\n",
    "        self.__weight_np = {}\n",
    "        self.__wvmodel = None\n",
    "#解析IMDB数据集，生成特征、标签和权重矩阵\n",
    "    def parse(self):\n",
    "        self.__wvmodel = gensim.models.KeyedVectors.load_word2vec_format(self.__glove_file)\n",
    "        for seg in self.__segs:\n",
    "# 解析IMDB数据\n",
    "            self.__parse_imdb_datas(seg)\n",
    "# 解析特征和标签\n",
    "            self.__parse_features_and_labels(seg)\n",
    "# 生成权重数组\n",
    "            self.__gen_weight_np(seg)\n",
    "#解析IMDB数据文件，获取文本和标签对应的列表\n",
    "    def __parse_imdb_datas(self, seg):\n",
    "        data_lists = []\n",
    "        for label_name, label_id in self.__label_dic.items():\n",
    "            sentence_dir = os.path.join(self.__imdb_path, seg, label_name)\n",
    "            for file in os.listdir(sentence_dir):\n",
    "                with open(os.path.join(sentence_dir, file), mode='r', encoding='utf8') as f:\n",
    "                    sentence = f.read().replace('\\n', '')\n",
    "                    data_lists.append([sentence, label_id])\n",
    "        self.__imdb_datas[seg] = data_lists\n",
    "    def __parse_features_and_labels(self, seg):\n",
    "        features = []\n",
    "        labels = []\n",
    "        for sentence, label in self.__imdb_datas[seg]:\n",
    "            features.append(sentence)\n",
    "            labels.append(label)\n",
    "        self.__features[seg] = features\n",
    "        self.__labels[seg] = labels\n",
    "# 更新特征为令牌化形式\n",
    "        self.__updata_features_to_tokenized(seg)\n",
    "# 解析词汇表\n",
    "        self.__parse_vacab(seg)\n",
    "# 编码特征\n",
    "        self.__encode_features(seg)\n",
    "# 填充特征\n",
    "        self.__padding_features(seg)\n",
    "#将特征（文本）转换为令牌化形式\n",
    "    def __updata_features_to_tokenized(self, seg):\n",
    "        tokenized_features = []\n",
    "        for sentence in self.__features[seg]:\n",
    "            tokenized_sentence = [word.lower() for word in sentence.split(\" \")]\n",
    "            tokenized_features.append(tokenized_sentence)\n",
    "        self.__features[seg] = tokenized_features\n",
    "#解析词汇表，生成词汇表和单词到索引的映射\n",
    "    def __parse_vacab(self, seg):\n",
    "        tokenized_features = self.__features[seg]\n",
    "        vocab = set(chain(*tokenized_features))\n",
    "        self.__vacab[seg] = vocab\n",
    "        word_to_idx = {word: i + 1 for i, word in enumerate(vocab)}\n",
    "        word_to_idx['<unk>'] = 0\n",
    "        self.__word2idx[seg] = word_to_idx\n",
    "#将特征（令牌化形式）编码为索引序列\n",
    "    def __encode_features(self, seg):\n",
    "        word_to_idx = self.__word2idx['train']\n",
    "        encoded_features = []\n",
    "        for tokenized_sentence in self.__features[seg]:\n",
    "            encoded_sentence = []\n",
    "            for word in tokenized_sentence:\n",
    "                encoded_sentence.append(word_to_idx.get(word, 0))\n",
    "            encoded_features.append(encoded_sentence)\n",
    "        self.__features[seg] = encoded_features\n",
    "#填充特征序列，使其具有相同的长度\n",
    "    def __padding_features(self, seg, maxlen=500, pad=0):\n",
    "        padded_features = []\n",
    "        for feature in self.__features[seg]:\n",
    "            if len(feature) >= maxlen:\n",
    "                padded_feature = feature[:maxlen]\n",
    "            else:\n",
    "                padded_feature = feature\n",
    "                while len(padded_feature) < maxlen:\n",
    "                    padded_feature.append(pad)\n",
    "            padded_features.append(padded_feature)\n",
    "        self.__features[seg] = padded_features\n",
    "#生成权重矩阵，用于将词汇转换为预训练的词向量\n",
    "    def __gen_weight_np(self, seg):\n",
    "        weight_np = np.zeros((len(self.__word2idx[seg]), self.__glove_dim), dtype=np.float32)\n",
    "        for word, idx in self.__word2idx[seg].items():\n",
    "            if word not in self.__wvmodel:\n",
    "                continue\n",
    "            word_vector = self.__wvmodel.get_vector(word)\n",
    "            weight_np[idx, :] = word_vector\n",
    "        self.__weight_np[seg] = weight_np\n",
    "#获取指定数据集的特征、标签和权重矩阵\n",
    "    def get_datas(self, seg):\n",
    "        features = np.array(self.__features[seg]).astype(np.int32)\n",
    "        labels = np.array(self.__labels[seg]).astype(np.int32)\n",
    "        weight = np.array(self.__weight_np[seg])\n",
    "        return features, labels, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ca4b686-79a6-41b0-bafc-a576d2fc13d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mindspore.dataset as ds\n",
    "from mindspore.mindrecord import FileWriter\n",
    "#创建MindSpore数据集\n",
    "def lstm_create_dataset(data_home, batch_size, repeat_num=1, training=True):\n",
    "    ds.config.set_seed(1)\n",
    "    data_dir = os.path.join(data_home, \"aclImdb_train.mindrecord0\")\n",
    "    if not training:\n",
    "        data_dir = os.path.join(data_home, \"aclImdb_test.mindrecord0\")\n",
    "# 从MindRecord文件中读取数据集\n",
    "    data_set = ds.MindDataset(data_dir, columns_list=[\"feature\", \"label\"], num_parallel_workers=4)\n",
    "# 对数据集进行洗牌\n",
    "    data_set = data_set.shuffle(buffer_size=data_set.get_dataset_size())\n",
    "# 按批次进行数据集划分\n",
    "    data_set = data_set.batch(batch_size=batch_size, drop_remainder=True)\n",
    "# 对数据集进行重复\n",
    "    data_set = data_set.repeat(count=repeat_num)\n",
    "    return data_set\n",
    "# 将特征和标签转换为MindRecord文件格式\n",
    "def _convert_to_mindrecord(data_home, features, labels, weight_np=None, training=True):\n",
    "    if weight_np is not None:\n",
    "        np.savetxt(os.path.join(data_home, 'weight.txt'), weight_np)\n",
    "    schema_json = {\"id\": {\"type\": \"int32\"},\n",
    "                   \"label\": {\"type\": \"int32\"},\n",
    "                   \"feature\": {\"type\": \"int32\", \"shape\": [-1]}}\n",
    "    data_dir = os.path.join(data_home, \"aclImdb_train.mindrecord\")\n",
    "    if not training:\n",
    "        data_dir = os.path.join(data_home, \"aclImdb_test.mindrecord\")\n",
    "    def get_imdb_data(features, labels):\n",
    "        data_list = []\n",
    "        for i, (label, feature) in enumerate(zip(labels, features)):\n",
    "            data_json = {\"id\": i,\n",
    "                         \"label\": int(label),\n",
    "                         \"feature\": feature.reshape(-1)}\n",
    "            data_list.append(data_json)\n",
    "        return data_list\n",
    "    writer = FileWriter(data_dir, shard_num=4)\n",
    "# 将数据转换为MindRecord的数据格式\n",
    "    data = get_imdb_data(features, labels)\n",
    "# 添加schema和索引\n",
    "    writer.add_schema(schema_json, \"nlp_schema\")\n",
    "    writer.add_index([\"id\", \"label\"])\n",
    "    writer.write_raw_data(data)\n",
    "    writer.commit()\n",
    "# 将数据集转换为MindRecord文件格式\n",
    "def convert_to_mindrecord(embed_size, aclimdb_path, preprocess_path, glove_path):\n",
    "    parser = ImdbParser(aclimdb_path, glove_path, embed_size)\n",
    "    parser.parse()\n",
    "    if not os.path.exists(preprocess_path):\n",
    "        print(f\"preprocess path {preprocess_path} is not exist\")\n",
    "        os.makedirs(preprocess_path)\n",
    "#获取训练集数据\n",
    "    train_features, train_labels, train_weight_np = parser.get_datas('train')\n",
    "    _convert_to_mindrecord(preprocess_path, train_features, train_labels, train_weight_np)\n",
    "# 获取测试集数据\n",
    "    test_features, test_labels, _ = parser.get_datas('test')\n",
    "    _convert_to_mindrecord(preprocess_path, test_features, test_labels, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83af692d-d3bd-4452-8f50-e5fdb6a05656",
   "metadata": {},
   "source": [
    "(4)模型构建\n",
    "\n",
    "导入初始化网络所需模块。\n",
    "\n",
    "定义需要单层LSTM小算子堆叠的设备类型。\n",
    "\n",
    "定义lstm_default_state函数来初始化网络参数及网络状态。\n",
    "\n",
    "定义stack_lstm_default_state函数来初始化小算子堆叠需要的初始化网络参数及网络状态。\n",
    "\n",
    "针对CPU场景，自定义单层LSTM小算子堆叠，来实现多层LSTM大算子功能。\n",
    "\n",
    "使用Cell方法，定义网络结构（SentimentNet网络）。\n",
    "\n",
    "实例化SentimentNet，创建网络，最后输出网络中加载的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff6ceecb-8e60-42fe-ba1c-2eb05564bb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "class SentimentNet(nn.Cell):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 embed_size,\n",
    "                 num_hiddens,\n",
    "                 num_layers,\n",
    "                 bidirectional,\n",
    "                 num_classes,\n",
    "                 weight,\n",
    "                 batch_size):\n",
    "        super(SentimentNet, self).__init__()\n",
    "# 创建嵌入层\n",
    "        self.embedding = nn.Embedding(vocab_size,\n",
    "                                      embed_size,\n",
    "                                      embedding_table=weight)\n",
    "        self.embedding.embedding_table.requires_grad = False\n",
    "# 转置操作\n",
    "        self.trans = ops.Transpose()\n",
    "        self.perm = (1, 0, 2)\n",
    "# 创建LSTM编码器\n",
    "        self.encoder = nn.LSTM(input_size=embed_size,\n",
    "                               hidden_size=num_hiddens,\n",
    "                               num_layers=num_layers,\n",
    "                               has_bias=True,\n",
    "                               bidirectional=bidirectional,\n",
    "                               dropout=0.0)\n",
    "# 拼接操作\n",
    "        self.concat = ops.Concat(1)\n",
    "# 创建全连接层作为解码器\n",
    "        if bidirectional:\n",
    "            self.decoder = nn.Dense(num_hiddens * 4, num_classes)\n",
    "        else:\n",
    "            self.decoder = nn.Dense(num_hiddens * 2, num_classes)\n",
    "    def construct(self, inputs):\n",
    "        embeddings = self.embedding(inputs)\n",
    "        embeddings = self.trans(embeddings, self.perm)\n",
    "        output, _ = self.encoder(embeddings)\n",
    "        encoding = self.concat((output[0], output[499]))\n",
    "        outputs = self.decoder(encoding)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ea5041-a82b-4783-98d1-2d2166fe5160",
   "metadata": {},
   "source": [
    "## 6 模型训练\n",
    "\n",
    "在训练前，需要对数据进行预处理。\n",
    "\n",
    "根据建立的LSTM模型，对模型进行训练：\n",
    "\n",
    "运行以下一段代码，创建优化器和损失函数模型，加载训练数据集（ds_train）并配置好CheckPoint生成信息，然后使用model.train接口，进行模型训练。根据输出可以看到loss值随着训练逐步降低。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15e017b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from mindspore import Tensor, nn, context, load_param_into_net, load_checkpoint\n",
    "from mindspore.train import LossMonitor, CheckpointConfig, ModelCheckpoint, TimeMonitor,Accuracy, Model\n",
    "# 如果条件为真，则执行以下代码块\n",
    "if 1:\n",
    "    args = args_train\n",
    "    cfg = lstm_cfg\n",
    "# 设置运行模式和设备目标\n",
    "    context.set_context(\n",
    "        mode=context.GRAPH_MODE,\n",
    "        save_graphs=False,\n",
    "        device_target=args.device_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d6fd8e",
   "metadata": {},
   "source": [
    "注意：存放预处理结果的目标文件夹如果已经生成了权重文件，以下代码不要重复运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84590b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Data Pre-processing ==============\n"
     ]
    }
   ],
   "source": [
    "#数据预处理，生成权重文件\n",
    "if args.preprocess == \"true\":\n",
    "    print(\"============== Starting Data Pre-processing ==============\")\n",
    "    convert_to_mindrecord(cfg.embed_size, args.aclimdb_path, args.preprocess_path, args.glove_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de7ef32",
   "metadata": {},
   "source": [
    "训练模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55bbbab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Training ==============\n",
      "epoch: 1 step: 1, loss is 0.693895697593689\n",
      "epoch: 1 step: 2, loss is 0.6929268836975098\n",
      "epoch: 1 step: 3, loss is 0.6929802298545837\n",
      "epoch: 1 step: 4, loss is 0.6938257813453674\n",
      "epoch: 1 step: 5, loss is 0.6931001543998718\n",
      "epoch: 1 step: 6, loss is 0.692486047744751\n",
      "epoch: 1 step: 7, loss is 0.6938748359680176\n",
      "epoch: 1 step: 8, loss is 0.6904892921447754\n",
      "epoch: 1 step: 9, loss is 0.6954400539398193\n",
      "epoch: 1 step: 10, loss is 0.6928492188453674\n",
      "epoch: 1 step: 11, loss is 0.6947997808456421\n",
      "epoch: 1 step: 12, loss is 0.6929847598075867\n",
      "epoch: 1 step: 13, loss is 0.6927945017814636\n",
      "epoch: 1 step: 14, loss is 0.6951846480369568\n",
      "epoch: 1 step: 15, loss is 0.6923548579216003\n",
      "epoch: 1 step: 16, loss is 0.6974267959594727\n",
      "epoch: 1 step: 17, loss is 0.691119372844696\n",
      "epoch: 1 step: 18, loss is 0.6984376311302185\n",
      "epoch: 1 step: 19, loss is 0.6991745829582214\n",
      "epoch: 1 step: 20, loss is 0.6967753171920776\n",
      "epoch: 1 step: 21, loss is 0.7002731561660767\n",
      "epoch: 1 step: 22, loss is 0.6923373937606812\n",
      "epoch: 1 step: 23, loss is 0.6916993260383606\n",
      "epoch: 1 step: 24, loss is 0.6955007314682007\n",
      "epoch: 1 step: 25, loss is 0.6921166181564331\n",
      "epoch: 1 step: 26, loss is 0.6904465556144714\n",
      "epoch: 1 step: 27, loss is 0.6996610760688782\n",
      "epoch: 1 step: 28, loss is 0.7016080021858215\n",
      "epoch: 1 step: 29, loss is 0.6929808259010315\n",
      "epoch: 1 step: 30, loss is 0.6998573541641235\n",
      "epoch: 1 step: 31, loss is 0.6905749440193176\n",
      "epoch: 1 step: 32, loss is 0.6902095675468445\n",
      "epoch: 1 step: 33, loss is 0.6919810175895691\n",
      "epoch: 1 step: 34, loss is 0.6896397471427917\n",
      "epoch: 1 step: 35, loss is 0.6904691457748413\n",
      "epoch: 1 step: 36, loss is 0.6904174089431763\n",
      "epoch: 1 step: 37, loss is 0.6949314475059509\n",
      "epoch: 1 step: 38, loss is 0.6935620307922363\n",
      "epoch: 1 step: 39, loss is 0.7003002166748047\n",
      "epoch: 1 step: 40, loss is 0.6923307776451111\n",
      "epoch: 1 step: 41, loss is 0.6929522752761841\n",
      "epoch: 1 step: 42, loss is 0.6910557150840759\n",
      "epoch: 1 step: 43, loss is 0.6903631687164307\n",
      "epoch: 1 step: 44, loss is 0.6900677680969238\n",
      "epoch: 1 step: 45, loss is 0.6935545206069946\n",
      "epoch: 1 step: 46, loss is 0.6946553587913513\n",
      "epoch: 1 step: 47, loss is 0.6814275979995728\n",
      "epoch: 1 step: 48, loss is 0.7044167518615723\n",
      "epoch: 1 step: 49, loss is 0.6964436769485474\n",
      "epoch: 1 step: 50, loss is 0.7097024321556091\n",
      "epoch: 1 step: 51, loss is 0.67820143699646\n",
      "epoch: 1 step: 52, loss is 0.6897562146186829\n",
      "epoch: 1 step: 53, loss is 0.6953971982002258\n",
      "epoch: 1 step: 54, loss is 0.6945570111274719\n",
      "epoch: 1 step: 55, loss is 0.6908230781555176\n",
      "epoch: 1 step: 56, loss is 0.6959161162376404\n",
      "epoch: 1 step: 57, loss is 0.6889438033103943\n",
      "epoch: 1 step: 58, loss is 0.6880387663841248\n",
      "epoch: 1 step: 59, loss is 0.6876860857009888\n",
      "epoch: 1 step: 60, loss is 0.6869718432426453\n",
      "epoch: 1 step: 61, loss is 0.6843722462654114\n",
      "epoch: 1 step: 62, loss is 0.6925888061523438\n",
      "epoch: 1 step: 63, loss is 0.6900920271873474\n",
      "epoch: 1 step: 64, loss is 0.7020215392112732\n",
      "epoch: 1 step: 65, loss is 0.7040388584136963\n",
      "epoch: 1 step: 66, loss is 0.6828406453132629\n",
      "epoch: 1 step: 67, loss is 0.6900355219841003\n",
      "epoch: 1 step: 68, loss is 0.6906041502952576\n",
      "epoch: 1 step: 69, loss is 0.6841505169868469\n",
      "epoch: 1 step: 70, loss is 0.6885021328926086\n",
      "epoch: 1 step: 71, loss is 0.6916016936302185\n",
      "epoch: 1 step: 72, loss is 0.698386013507843\n",
      "epoch: 1 step: 73, loss is 0.686960756778717\n",
      "epoch: 1 step: 74, loss is 0.6914469003677368\n",
      "epoch: 1 step: 75, loss is 0.6799991726875305\n",
      "epoch: 1 step: 76, loss is 0.6871197819709778\n",
      "epoch: 1 step: 77, loss is 0.689686119556427\n",
      "epoch: 1 step: 78, loss is 0.6866224408149719\n",
      "epoch: 1 step: 79, loss is 0.6947789788246155\n",
      "epoch: 1 step: 80, loss is 0.6914535760879517\n",
      "epoch: 1 step: 81, loss is 0.6875796914100647\n",
      "epoch: 1 step: 82, loss is 0.6858627796173096\n",
      "epoch: 1 step: 83, loss is 0.6844422817230225\n",
      "epoch: 1 step: 84, loss is 0.6736572980880737\n",
      "epoch: 1 step: 85, loss is 0.696653425693512\n",
      "epoch: 1 step: 86, loss is 0.6855999827384949\n",
      "epoch: 1 step: 87, loss is 0.6825664639472961\n",
      "epoch: 1 step: 88, loss is 0.6854674220085144\n",
      "epoch: 1 step: 89, loss is 0.686680793762207\n",
      "epoch: 1 step: 90, loss is 0.6825083494186401\n",
      "epoch: 1 step: 91, loss is 0.6897419095039368\n",
      "epoch: 1 step: 92, loss is 0.6791043281555176\n",
      "epoch: 1 step: 93, loss is 0.6897247433662415\n",
      "epoch: 1 step: 94, loss is 0.6927436590194702\n",
      "epoch: 1 step: 95, loss is 0.6818466782569885\n",
      "epoch: 1 step: 96, loss is 0.6817553639411926\n",
      "epoch: 1 step: 97, loss is 0.6846815943717957\n",
      "epoch: 1 step: 98, loss is 0.6891971230506897\n",
      "epoch: 1 step: 99, loss is 0.6852508783340454\n",
      "epoch: 1 step: 100, loss is 0.6920838952064514\n",
      "epoch: 1 step: 101, loss is 0.6718142032623291\n",
      "epoch: 1 step: 102, loss is 0.680147111415863\n",
      "epoch: 1 step: 103, loss is 0.6863728761672974\n",
      "epoch: 1 step: 104, loss is 0.6883713603019714\n",
      "epoch: 1 step: 105, loss is 0.6800605654716492\n",
      "epoch: 1 step: 106, loss is 0.6814717650413513\n",
      "epoch: 1 step: 107, loss is 0.6866250038146973\n",
      "epoch: 1 step: 108, loss is 0.7302982211112976\n",
      "epoch: 1 step: 109, loss is 0.6663404107093811\n",
      "epoch: 1 step: 110, loss is 0.695202648639679\n",
      "epoch: 1 step: 111, loss is 0.6807718276977539\n",
      "epoch: 1 step: 112, loss is 0.6770272254943848\n",
      "epoch: 1 step: 113, loss is 0.691717803478241\n",
      "epoch: 1 step: 114, loss is 0.6676583886146545\n",
      "epoch: 1 step: 115, loss is 0.7014309763908386\n",
      "epoch: 1 step: 116, loss is 0.6777395606040955\n",
      "epoch: 1 step: 117, loss is 0.6831545233726501\n",
      "epoch: 1 step: 118, loss is 0.6594783067703247\n",
      "epoch: 1 step: 119, loss is 0.6623108386993408\n",
      "epoch: 1 step: 120, loss is 0.6848569512367249\n",
      "epoch: 1 step: 121, loss is 0.6750605702400208\n",
      "epoch: 1 step: 122, loss is 0.7360871434211731\n",
      "epoch: 1 step: 123, loss is 0.6797394156455994\n",
      "epoch: 1 step: 124, loss is 0.6741750240325928\n",
      "epoch: 1 step: 125, loss is 0.6756862998008728\n",
      "epoch: 1 step: 126, loss is 0.6972788572311401\n",
      "epoch: 1 step: 127, loss is 0.6721870303153992\n",
      "epoch: 1 step: 128, loss is 0.6703335642814636\n",
      "epoch: 1 step: 129, loss is 0.6935925483703613\n",
      "epoch: 1 step: 130, loss is 0.6851807832717896\n",
      "epoch: 1 step: 131, loss is 0.6750279068946838\n",
      "epoch: 1 step: 132, loss is 0.6515899300575256\n",
      "epoch: 1 step: 133, loss is 0.6680722236633301\n",
      "epoch: 1 step: 134, loss is 0.7080857753753662\n",
      "epoch: 1 step: 135, loss is 0.6892257332801819\n",
      "epoch: 1 step: 136, loss is 0.707385778427124\n",
      "epoch: 1 step: 137, loss is 0.6921881437301636\n",
      "epoch: 1 step: 138, loss is 0.6587196588516235\n",
      "epoch: 1 step: 139, loss is 0.6808371543884277\n",
      "epoch: 1 step: 140, loss is 0.6867881417274475\n",
      "epoch: 1 step: 141, loss is 0.6592063903808594\n",
      "epoch: 1 step: 142, loss is 0.7101094126701355\n",
      "epoch: 1 step: 143, loss is 0.6535089015960693\n",
      "epoch: 1 step: 144, loss is 0.6677118539810181\n",
      "epoch: 1 step: 145, loss is 0.647622287273407\n",
      "epoch: 1 step: 146, loss is 0.673795223236084\n",
      "epoch: 1 step: 147, loss is 0.6689448356628418\n",
      "epoch: 1 step: 148, loss is 0.6591368317604065\n",
      "epoch: 1 step: 149, loss is 0.6987086534500122\n",
      "epoch: 1 step: 150, loss is 0.6628687381744385\n",
      "epoch: 1 step: 151, loss is 0.6634705066680908\n",
      "epoch: 1 step: 152, loss is 0.6823620796203613\n",
      "epoch: 1 step: 153, loss is 0.6729041337966919\n",
      "epoch: 1 step: 154, loss is 0.6683645844459534\n",
      "epoch: 1 step: 155, loss is 0.6675894260406494\n",
      "epoch: 1 step: 156, loss is 0.6599823236465454\n",
      "epoch: 1 step: 157, loss is 0.6627787947654724\n",
      "epoch: 1 step: 158, loss is 0.6520675420761108\n",
      "epoch: 1 step: 159, loss is 0.6961470246315002\n",
      "epoch: 1 step: 160, loss is 0.6366196274757385\n",
      "epoch: 1 step: 161, loss is 0.6369083523750305\n",
      "epoch: 1 step: 162, loss is 0.6260628700256348\n",
      "epoch: 1 step: 163, loss is 0.6418289542198181\n",
      "epoch: 1 step: 164, loss is 0.6616230010986328\n",
      "epoch: 1 step: 165, loss is 0.691646933555603\n",
      "epoch: 1 step: 166, loss is 0.6746764183044434\n",
      "epoch: 1 step: 167, loss is 0.6673591732978821\n",
      "epoch: 1 step: 168, loss is 0.6513610482215881\n",
      "epoch: 1 step: 169, loss is 0.6620081663131714\n",
      "epoch: 1 step: 170, loss is 0.652692437171936\n",
      "epoch: 1 step: 171, loss is 0.6798731088638306\n",
      "epoch: 1 step: 172, loss is 0.6553304195404053\n",
      "epoch: 1 step: 173, loss is 0.5885493159294128\n",
      "epoch: 1 step: 174, loss is 0.667552649974823\n",
      "epoch: 1 step: 175, loss is 0.6536681056022644\n",
      "epoch: 1 step: 176, loss is 0.614195704460144\n",
      "epoch: 1 step: 177, loss is 0.6347478628158569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 178, loss is 0.6696520447731018\n",
      "epoch: 1 step: 179, loss is 0.666671633720398\n",
      "epoch: 1 step: 180, loss is 0.6843529343605042\n",
      "epoch: 1 step: 181, loss is 0.6474733948707581\n",
      "epoch: 1 step: 182, loss is 0.6565805673599243\n",
      "epoch: 1 step: 183, loss is 0.660170316696167\n",
      "epoch: 1 step: 184, loss is 0.648608922958374\n",
      "epoch: 1 step: 185, loss is 0.6621960401535034\n",
      "epoch: 1 step: 186, loss is 0.6408436894416809\n",
      "epoch: 1 step: 187, loss is 0.6026341319084167\n",
      "epoch: 1 step: 188, loss is 0.6355273723602295\n",
      "epoch: 1 step: 189, loss is 0.5880937576293945\n",
      "epoch: 1 step: 190, loss is 0.5902379155158997\n",
      "epoch: 1 step: 191, loss is 0.6481162905693054\n",
      "epoch: 1 step: 192, loss is 0.6000613570213318\n",
      "epoch: 1 step: 193, loss is 0.5818831324577332\n",
      "epoch: 1 step: 194, loss is 0.6269707679748535\n",
      "epoch: 1 step: 195, loss is 0.6468162536621094\n",
      "Train epoch time: 3061722.619 ms, per step time: 15701.142 ms\n",
      "============== Training Success ==============\n"
     ]
    }
   ],
   "source": [
    "#加载嵌入矩阵\n",
    "embedding_table = np.loadtxt(os.path.join(args.preprocess_path, \"weight.txt\")).astype(np.float32)\n",
    "# 创建网络\n",
    "network = SentimentNet(vocab_size=embedding_table.shape[0],\n",
    "                           embed_size=cfg.embed_size,\n",
    "                           num_hiddens=cfg.num_hiddens,\n",
    "                           num_layers=cfg.num_layers,\n",
    "                           bidirectional=cfg.bidirectional,\n",
    "                           num_classes=cfg.num_classes,\n",
    "                           weight=Tensor(embedding_table),\n",
    "                           batch_size=cfg.batch_size)\n",
    "# 加载预训练模型参数\n",
    "if args.pre_trained:\n",
    "    load_param_into_net(network, load_checkpoint(args.pre_trained))\n",
    "# 定义损失函数、优化器和评价指标\n",
    "loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "opt = nn.Momentum(network.trainable_params(), cfg.learning_rate, cfg.momentum)\n",
    "loss_cb = LossMonitor()\n",
    "model = Model(network, loss, opt, {'acc': Accuracy()})\n",
    "print(\"============== Starting Training ==============\")\n",
    "# 训练模型\n",
    "num_steps = 10\n",
    "ds_train = lstm_create_dataset(args.preprocess_path, cfg.batch_size, 1)\n",
    "config_ck = CheckpointConfig(save_checkpoint_steps=cfg.save_checkpoint_steps,\n",
    "                                 keep_checkpoint_max=cfg.keep_checkpoint_max)\n",
    "ckpoint_cb = ModelCheckpoint(prefix=\"lstm\", directory=args.ckpt_path, config=config_ck)\n",
    "time_cb = TimeMonitor(data_size=ds_train.get_dataset_size())\n",
    "# 根据设备目标选择训练方式\n",
    "if args.device_target == \"CPU\":\n",
    "    model.train(cfg.num_epochs, ds_train, callbacks=[time_cb, ckpoint_cb, loss_cb], dataset_sink_mode=False)\n",
    "else:\n",
    "    model.train(cfg.num_epochs, ds_train, callbacks=[time_cb, ckpoint_cb, loss_cb])\n",
    "print(\"============== Training Success ==============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3746b878-81fa-43c4-8e20-e9a074ec46e6",
   "metadata": {},
   "source": [
    "## 7 模型测试\n",
    "根据处理后的测试数据以及建立的LSTM模型，对模型进行测试：\n",
    "\n",
    "创建并加载验证数据集（ds_eval），加载由训练保存的CheckPoint文件，进行验证，查看模型质量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9399bab-daec-48ca-bc28-39bc9696dea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Testing ==============\n",
      "============== {'acc': 0.6401842948717948} ==============\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from mindspore import Tensor, nn, context, load_checkpoint, load_param_into_net\n",
    "from mindspore.train import Accuracy\n",
    "from mindspore.train import LossMonitor, Model\n",
    "if 1:\n",
    "    args = args_test\n",
    "    context.set_context(\n",
    "        mode=context.GRAPH_MODE,\n",
    "        save_graphs=False,\n",
    "        device_target=args.device_target)\n",
    "    if args.preprocess == \"true\":\n",
    "        print(\"============== Starting Data Pre-processing ==============\")\n",
    "        convert_to_mindrecord(cfg.embed_size, args.aclimdb_path, args.preprocess_path, args.glove_path)\n",
    "    embedding_table = np.loadtxt(os.path.join(args.preprocess_path, \"weight.txt\")).astype(np.float32)\n",
    "    network = SentimentNet(vocab_size=embedding_table.shape[0],\n",
    "                           embed_size=cfg.embed_size,\n",
    "                           num_hiddens=cfg.num_hiddens,\n",
    "                           num_layers=cfg.num_layers,\n",
    "                           bidirectional=cfg.bidirectional,\n",
    "                           num_classes=cfg.num_classes,\n",
    "                           weight=Tensor(embedding_table),\n",
    "                           batch_size=cfg.batch_size)\n",
    "# 定义损失函数和优化器\n",
    "    loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "    opt = nn.Momentum(network.trainable_params(), cfg.learning_rate, cfg.momentum)\n",
    "# 定义评估指标\n",
    "    loss_cb = LossMonitor()\n",
    "    model = Model(network, loss, opt, {'acc': Accuracy()})\n",
    "    print(\"============== Starting Testing ==============\")\n",
    "# 创建评估数据集\n",
    "    ds_eval = lstm_create_dataset(args.preprocess_path, cfg.batch_size, training=False)\n",
    "    param_dict = load_checkpoint(args.ckpt_path)\n",
    "# 加载训练好的模型参数\n",
    "    load_param_into_net(network, param_dict)\n",
    "# 在设备上进行评估\n",
    "    if args.device_target == \"CPU\":\n",
    "        acc = model.eval(ds_eval, dataset_sink_mode=False)\n",
    "    else:\n",
    "        acc = model.eval(ds_eval)\n",
    "    print(\"============== {} ==============\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bfa5f4",
   "metadata": {},
   "source": [
    "## 8 实验总结\n",
    "\n",
    "以上便完成了MindSpore自然语言处理应用的体验，通过本次体验全面了解了如何使用MindSpore进行自然语言中处理情感分类问题，理解了如何通过定义和初始化基于LSTM的SentimentNet网络进行训练模型及验证正确率。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
